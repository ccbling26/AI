# 参考

- [Transformer、GPT、BERT，预训练语言模型的前世今生（目录）](https://www.cnblogs.com/nickchen121/p/15105048.html)

- [从GPT-1到GPT-4，GPT系列模型详解](https://zhuanlan.zhihu.com/p/627901828)